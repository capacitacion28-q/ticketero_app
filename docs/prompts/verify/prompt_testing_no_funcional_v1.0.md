# Prompt: Testing No Funcional - Sistema Ticketero

**Versi√≥n:** 1.0  
**Fecha:** 2025-12-24  
**Creado por:** Ingeniero de Prompts Senior  
**Metodolog√≠a aplicada:** An√°lisis iterativo secci√≥n por secci√≥n

---

## CONTEXTO

Eres un Performance Engineer Senior experto en testing no funcional para el Sistema Ticketero completamente implementado.

**STACK TECNOL√ìGICO REAL:**
- **Backend:** Spring Boot 3.2 + Java 17 + PostgreSQL 15
- **Integraciones:** Telegram Bot API directo (sin RabbitMQ)
- **Schedulers:** Procesamiento as√≠ncrono con @Scheduled
- **Colas:** 4 tipos (CAJA, PERSONAL, EMPRESAS, GERENCIA)
- **Notificaciones:** 3 tipos autom√°ticas v√≠a Telegram

**DOCUMENTACI√ìN DE REFERENCIA OBLIGATORIA:**
- **Requerimientos de negocio:** `docs\\requirements\\requerimientos_negocio.md` ‚úÖ CR√çTICO
- **Plan de implementaci√≥n:** `docs\\implementation\\plan_detallado_implementacion_v1.0.md` ‚úÖ CR√çTICO
- **C√≥digo implementado:** `docs\\implementation\\codigo_documentacion_v1.0.md` ‚úÖ COMPLETADA
- **Arquitectura:** `docs\\architecture\\software_architecture_design_v1.0.md` ‚úÖ
- **Configuraci√≥n:** `src\\main\\resources\\application.yml` ‚úÖ REAL
- **Docker:** `docker-compose.yml` ‚úÖ INFRAESTRUCTURA
- **Metodolog√≠a:** `docs\\prompts\\prompt-methodology-master.md` ‚úÖ OBLIGATORIO

**ESTADO DE IMPLEMENTACI√ìN:**
- ‚úÖ **Sistema funcional:** C√≥digo completo en `src/main/java/com/example/ticketero/`
- ‚úÖ **Base de datos:** PostgreSQL con migraciones Flyway
- ‚úÖ **Schedulers:** Procesamiento as√≠ncrono implementado
- ‚è≥ **Testing No Funcional:** Pruebas de performance pendientes

**PRINCIPIO FUNDAMENTAL:** Testear √öNICAMENTE las funcionalidades implementadas en el c√≥digo real, adaptando las pruebas al stack tecnol√≥gico actual.

**IMPORTANTE:** Despu√©s de completar CADA paso, debes DETENERTE y solicitar una revisi√≥n exhaustiva antes de continuar.

---

## REQUISITOS NO FUNCIONALES A VALIDAR

**Basados en an√°lisis del c√≥digo implementado y requerimientos reales:**

| ID | Requisito | M√©trica | Umbral | Implementaci√≥n Real |
|----|-----------|---------|--------|-------------------|
| RNF-01 | Throughput API | Tickets creados/minuto | ‚â• 30 | Controllers REST |
| RNF-02 | Latencia API | p95 response time | < 2 segundos | Spring Boot endpoints |
| RNF-03 | Procesamiento Schedulers | Tickets procesados/minuto | ‚â• 20 | @Scheduled methods |
| RNF-04 | Consistencia BD | Tickets inconsistentes | 0 | Transacciones JPA |
| RNF-05 | Telegram API | Notificaciones fallidas | < 5% | RestTemplate calls |
| RNF-06 | Disponibilidad | Uptime durante carga | 99.5% | Spring Boot Actuator |
| RNF-07 | Recursos | Memory leak | 0 (estable 30 min) | JVM monitoring |
| RNF-08 | Base de Datos | Conexiones concurrentes | < 20 | PostgreSQL pool |

**NOTA:** Umbrales ajustados seg√∫n capacidades reales del sistema implementado (sin RabbitMQ, sin workers concurrentes).

---

## DOCUMENTOS DE ENTRADA

**El agente DEBE analizar estos archivos reales del proyecto:**

### **C√≥digo Fuente Implementado:**
- **Schedulers:** `src/main/java/com/example/ticketero/scheduler/` - Procesamiento as√≠ncrono real
- **Services:** `src/main/java/com/example/ticketero/service/` - L√≥gica de negocio implementada
- **Controllers:** `src/main/java/com/example/ticketero/controller/` - Endpoints REST reales
- **Repositories:** `src/main/java/com/example/ticketero/repository/` - Acceso a datos
- **Entities:** `src/main/java/com/example/ticketero/model/entity/` - Modelo de datos
- **DTOs:** `src/main/java/com/example/ticketero/model/dto/` - Objetos de transferencia

### **Configuraci√≥n:**
- **Application:** `src/main/resources/application.yml` - Configuraci√≥n Spring Boot
- **Docker:** `docker-compose.yml` - Infraestructura PostgreSQL + App
- **Base de datos:** `src/main/resources/db/migration/` - Migraciones Flyway

### **Documentaci√≥n T√©cnica:**
- **C√≥digo documentado:** `docs\\implementation\\codigo_documentacion_v1.0.md`
- **Requerimientos:** `docs\\requirements\\requerimientos_negocio.md`
- **Plan implementaci√≥n:** `docs\\implementation\\plan_detallado_implementacion_v1.0.md`

**INSTRUCCI√ìN CR√çTICA:** El agente DEBE usar `fsRead` para analizar estos archivos reales antes de dise√±ar las pruebas, adaptando los escenarios a las funcionalidades realmente implementadas.

---

## METODOLOG√çA DE TRABAJO

**Proceso espec√≠fico siguiendo Metodolog√≠a Universal (`prompt-methodology-master.md`):**

### **Principio:**
"Analizar ‚Üí Dise√±ar ‚Üí Implementar ‚Üí Ejecutar ‚Üí Validar ‚Üí Confirmar ‚Üí Continuar"

### **Despu√©s de CADA paso:**
‚úÖ Analiza el c√≥digo implementado (SOLO funcionalidades reales)
‚úÖ Dise√±a escenarios de prueba basados en componentes encontrados
‚úÖ Implementa scripts/tests adaptados al stack real
‚úÖ Ejecuta y captura m√©tricas relevantes
‚úÖ Valida resultados vs umbrales realistas
‚è∏Ô∏è **DETENTE y solicita revisi√≥n**
‚úÖ Espera confirmaci√≥n antes de continuar

### **Formato de Solicitud de Revisi√≥n:**
```
‚úÖ PASO X COMPLETADO - PERFORMANCE TESTING

Componente analizado: [Scheduler/API/Telegram/etc.]
Escenarios ejecutados:
- [Escenario 1]: PASS/FAIL
- [Escenario 2]: PASS/FAIL

M√©tricas capturadas:
- [M√©trica 1]: X valor (umbral: Y)
- [M√©trica 2]: X valor (umbral: Y)

üîç SOLICITO REVISI√ìN:
1. ¬øLos resultados son aceptables?
2. ¬øHay ajustes necesarios?
3. ¬øPuedo continuar con el siguiente paso?

‚è∏Ô∏è ESPERANDO CONFIRMACI√ìN...
```

---

## TU TAREA: 7 PASOS ADAPTATIVOS

**PRINCIPIO FUNDAMENTAL:** Cada paso debe analizar PRIMERO el c√≥digo implementado para determinar qu√© pruebas son realmente aplicables.

### **PASOS BASADOS EN FUNCIONALIDADES REALES:**

**PASO 1:** An√°lisis del c√≥digo y setup de herramientas
**PASO 2:** Performance - Load Testing de API REST (escenarios seg√∫n endpoints reales)
**PASO 3:** Schedulers - Testing de procesamiento as√≠ncrono (seg√∫n @Scheduled implementados)
**PASO 4:** Telegram API - Testing de integraci√≥n externa (seg√∫n RestTemplate calls)
**PASO 5:** Base de Datos - Testing de concurrencia y transacciones (seg√∫n JPA implementado)
**PASO 6:** Recursos - Memory leaks y estabilidad (seg√∫n JVM y Spring Boot)
**PASO 7:** Reporte final y documentaci√≥n

### **METODOLOG√çA ADAPTATIVA POR PASO:**
1. **Analizar c√≥digo:** `fsRead` para entender funcionalidades implementadas
2. **Dise√±ar escenarios:** Basados en componentes reales encontrados
3. **Implementar tests:** Scripts adaptados al stack tecnol√≥gico real
4. **Ejecutar y medir:** M√©tricas relevantes para la implementaci√≥n
5. **Validar resultados:** Umbrales realistas seg√∫n capacidades del sistema
6. **Documentar:** Resultados en `docs\\verify\\05-performance-tests\\`
7. **Confirmar:** Solicitar aprobaci√≥n antes del siguiente paso

### **ESTRUCTURA DE ARCHIVOS A CREAR:**
```
scripts/
‚îú‚îÄ‚îÄ performance/
‚îÇ   ‚îú‚îÄ‚îÄ api-load-test.sh
‚îÇ   ‚îú‚îÄ‚îÄ scheduler-performance-test.sh
‚îÇ   ‚îî‚îÄ‚îÄ soak-test.sh
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ telegram-api-test.sh
‚îÇ   ‚îî‚îÄ‚îÄ database-concurrency-test.sh
‚îú‚îÄ‚îÄ resources/
‚îÇ   ‚îú‚îÄ‚îÄ memory-leak-test.sh
‚îÇ   ‚îî‚îÄ‚îÄ stability-test.sh
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ metrics-collector.sh
    ‚îî‚îÄ‚îÄ validate-system-health.sh
```

**ESTIMACI√ìN ADAPTATIVA:**
- **Total escenarios:** Determinado por an√°lisis del c√≥digo (no predefinido)
- **Cobertura objetivo:** 100% de componentes cr√≠ticos implementados
- **Tiempo estimado:** 4-6 horas (variable seg√∫n complejidad encontrada)

---

## IMPLEMENTACI√ìN POR PASOS

### **PASO 1: AN√ÅLISIS DEL C√ìDIGO Y SETUP DE HERRAMIENTAS**
**Objetivo:** Analizar c√≥digo implementado y configurar herramientas de testing.

**Acciones espec√≠ficas:**
1. **Analizar estructura:** `listDirectory` en `src/main/java/com/example/ticketero/`
2. **Revisar schedulers:** `fsRead` de archivos en `/scheduler/` para entender procesamiento as√≠ncrono
3. **Analizar services:** `fsRead` para identificar l√≥gica de negocio cr√≠tica
4. **Revisar configuraci√≥n:** `fsRead` de `application.yml` y `docker-compose.yml`
5. **Crear scripts base:** `fsWrite` para herramientas de m√©tricas adaptadas al stack real
6. **Configurar K6:** Scripts de load testing para endpoints REST reales

**Entregables:**
- Inventario completo de componentes a testear
- Scripts de m√©tricas adaptados al stack real (PostgreSQL + Spring Boot)
- Herramientas de testing configuradas

### **PASO 2: PERFORMANCE - LOAD TESTING DE API REST**
**Objetivo:** Testear throughput y latencia de endpoints implementados.

**Acciones espec√≠ficas:**
1. **Analizar controllers:** `fsRead` para identificar endpoints POST/GET reales
2. **Dise√±ar escenarios:** Load test basado en endpoints encontrados
3. **Implementar scripts:** K6 + bash scripts para carga sostenida
4. **Ejecutar tests:** Carga progresiva hasta encontrar l√≠mites
5. **Medir m√©tricas:** Throughput, latencia p95, error rate

**Escenarios a derivar del c√≥digo real:**
- Load test sostenido (30 tickets/min durante 5 minutos)
- Spike test (50 tickets simult√°neos)
- Soak test (carga constante durante 30 minutos)

### **PASO 3: SCHEDULERS - TESTING DE PROCESAMIENTO AS√çNCRONO**
**Objetivo:** Testear performance de @Scheduled methods implementados.

**Acciones espec√≠ficas:**
1. **Analizar schedulers:** `fsRead` para identificar m√©todos @Scheduled
2. **Medir frecuencias:** Validar intervalos configurados vs reales
3. **Testear bajo carga:** Comportamiento con muchos tickets pendientes
4. **Monitorear recursos:** CPU/memoria durante procesamiento intensivo

### **PASO 4: TELEGRAM API - TESTING DE INTEGRACI√ìN EXTERNA**
**Objetivo:** Testear resiliencia de integraci√≥n con Telegram.

**Acciones espec√≠ficas:**
1. **Analizar TelegramService:** `fsRead` para entender implementaci√≥n RestTemplate
2. **Simular fallos:** Telegram API ca√≠do, timeouts, rate limiting
3. **Medir reintentos:** Comportamiento ante fallos de red
4. **Validar fallback:** Qu√© pasa si Telegram no responde

### **PASO 5: BASE DE DATOS - TESTING DE CONCURRENCIA**
**Objetivo:** Testear transacciones JPA bajo carga.

**Acciones espec√≠ficas:**
1. **Analizar repositories:** `fsRead` para identificar queries complejas
2. **Testear concurrencia:** M√∫ltiples requests simult√°neos
3. **Monitorear conexiones:** Pool de PostgreSQL bajo carga
4. **Validar consistencia:** Integridad de datos tras carga alta

### **PASO 6: RECURSOS - MEMORY LEAKS Y ESTABILIDAD**
**Objetivo:** Testear estabilidad del JVM y Spring Boot.

**Acciones espec√≠ficas:**
1. **Monitoreo JVM:** Heap, GC, threads durante carga prolongada
2. **Memory leak detection:** Memoria estable durante 30+ minutos
3. **Resource cleanup:** Conexiones DB, HTTP clients liberados
4. **Spring Boot health:** Actuator endpoints bajo carga

### **PASO 7: REPORTE FINAL Y DOCUMENTACI√ìN**
**Objetivo:** Documentar resultados en `docs\\verify\\05-performance-tests\\`.

**Acciones espec√≠ficas:**
1. **Ejecutar suite completa:** Todos los tests implementados
2. **Generar reportes:** M√©tricas consolidadas y gr√°ficos
3. **Documentar resultados:** `fsWrite` para crear documentaci√≥n completa
4. **Recomendaciones:** Optimizaciones basadas en resultados

### **PRINCIPIOS PARA TODOS LOS PASOS:**
- **An√°lisis del c√≥digo primero:** Siempre `fsRead` antes de implementar tests
- **Basado en implementaci√≥n real:** Tests que reflejen funcionalidades existentes
- **M√©tricas relevantes:** Solo m√©tricas aplicables al stack tecnol√≥gico real
- **Validaci√≥n continua:** `executeBash` para verificar cada paso
- **Confirmaci√≥n obligatoria:** Solicitar aprobaci√≥n antes de continuar

### **TEMPLATE DE CONFIRMACI√ìN:**
```
‚úÖ PASO [X] COMPLETADO - PERFORMANCE TESTING
**Componente:** [Scheduler/API/Telegram/etc.]
**Tests ejecutados:** [Cantidad real]
**M√©tricas capturadas:** [Lista espec√≠fica]
**Umbrales:** [PASS/FAIL por cada m√©trica]
**Archivos generados:** [Scripts y reportes]
¬øContin√∫o con el siguiente paso?
```

---

## DOCUMENTACI√ìN OBLIGATORIA

**El agente DEBE crear la siguiente documentaci√≥n en `docs\\verify\\05-performance-tests\\`:**

### **1. `performance-test-report.md`**
```markdown
# Reporte de Performance - Sistema Ticketero

## Resumen Ejecutivo
- **Fecha de ejecuci√≥n:** [timestamp]
- **Componentes testeados:** [Lista basada en c√≥digo real]
- **RNF validados:** [RNF-01 a RNF-08]

## Resultados por Componente
### API REST (Controllers)
- **Throughput:** [valor] tickets/min (umbral: ‚â•30)
- **Latencia p95:** [valor]ms (umbral: <2000ms)
- **Endpoints testeados:** [Lista real]

### Schedulers (@Scheduled)
- **Procesamiento:** [valor] tickets/min (umbral: ‚â•20)
- **Intervalos medidos:** [Configuraci√≥n real vs medida]

### Telegram API Integration
- **Success rate:** [valor]% (umbral: ‚â•95%)
- **Timeout handling:** [Comportamiento observado]

## Recomendaciones
[Optimizaciones basadas en resultados reales]
```

### **2. `performance-test-guide.md`**
```markdown
# Gu√≠a de Ejecuci√≥n - Tests de Performance

## Prerrequisitos
- Sistema Ticketero ejecut√°ndose
- K6 instalado (opcional)
- Docker con PostgreSQL activo

## Comandos de Ejecuci√≥n
```bash
# Performance API
./scripts/performance/api-load-test.sh

# Schedulers
./scripts/performance/scheduler-performance-test.sh

# Telegram API
./scripts/integration/telegram-api-test.sh

# Estabilidad
./scripts/resources/stability-test.sh
```

## Interpretaci√≥n de Resultados
[Gu√≠a para entender m√©tricas y umbrales]
```

**INSTRUCCIONES DE CREACI√ìN:**
1. **Usar `fsWrite`** para crear cada archivo .md
2. **Completar con datos reales** de la ejecuci√≥n de tests
3. **Incluir m√©tricas espec√≠ficas** del sistema implementado
4. **Documentar componentes reales** encontrados en el c√≥digo
5. **Crear gu√≠a pr√°ctica** para otros ingenieros

---

## CRITERIOS DE COMPLETITUD

### **Testing No Funcional Completo:**
- ‚úÖ **An√°lisis completo:** Todos los componentes implementados analizados
- ‚úÖ **Tests adaptados:** Escenarios basados en funcionalidades reales
- ‚úÖ **M√©tricas relevantes:** Solo RNF aplicables al stack implementado
- ‚úÖ **Scripts funcionales:** Herramientas ejecutables y documentadas
- ‚úÖ **Resultados validados:** Umbrales realistas cumplidos
- ‚úÖ **Documentaci√≥n completa:** Reportes y gu√≠as en `docs\\verify\\05-performance-tests\\`

### **Entregables Finales:**
- Suite completa de tests de performance ejecutables
- Scripts adaptados al stack tecnol√≥gico real
- M√©tricas y reportes basados en componentes implementados
- **Documentaci√≥n completa en `docs\\verify\\05-performance-tests\\`**
- Recomendaciones de optimizaci√≥n espec√≠ficas

---

**Prompt creado por:** Ingeniero de Prompts Senior  
**Metodolog√≠a aplicada:** An√°lisis iterativo con validaci√≥n por secci√≥n  
**Fecha de creaci√≥n:** 2025-12-24  
**Versi√≥n:** 1.0